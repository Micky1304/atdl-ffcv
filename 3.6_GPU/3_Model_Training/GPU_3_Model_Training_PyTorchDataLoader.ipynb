{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4b823aa-6eed-48c2-a1d1-fcda131b6417",
   "metadata": {},
   "source": [
    "# End-to-end training in CPU environment with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb88579-2b68-4139-94af-08cfc7f2598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a340982d-d982-4e77-ad5e-19f579570617",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.file_list = [f for f in os.listdir(data_dir) if f.startswith(\"part_\")]\n",
    "        self.labels = np.load(os.path.join(data_dir, \"labels.npy\"), allow_pickle = True).item()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.data_dir, self.file_list[idx])\n",
    "        image = np.load(file_path)\n",
    "        label = self.labels[self.file_list[idx]]\n",
    "        return image, label\n",
    "\n",
    "data_dir = \"data/train_small_npy\"\n",
    "\n",
    "dataset = CustomDataset(data_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=48, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "522c5e74-7f70-45f2-8679-b235c4a275dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 125 * 125, 200)\n",
    "        self.fc2 = nn.Linear(200, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 32 * 125 * 125)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c02531-b4c7-4a88-95ea-6b6a4f63dcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 done in 10.538519620895386 seconds.\n",
      "Epoch 2 done in 10.11624526977539 seconds.\n",
      "Epoch 3 done in 10.337998867034912 seconds.\n",
      "Epoch 4 done in 10.112791538238525 seconds.\n",
      "Epoch 5 done in 10.186606884002686 seconds.\n",
      "Epoch 6 done in 10.156364679336548 seconds.\n",
      "Epoch 7 done in 10.214253425598145 seconds.\n",
      "Epoch 8 done in 10.150419473648071 seconds.\n",
      "Epoch 9 done in 10.034946203231812 seconds.\n",
      "Epoch 10 done in 10.226240396499634 seconds.\n",
      "Total time taken: 102.07669496536255 seconds\n",
      "Total time per epoch: 10.207669496536255 seconds\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "custom_transform = transforms.Compose([\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomRotation(90),\n",
    "    transforms.RandomCrop((500, 500))\n",
    "])\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        transformed_images = torch.stack([custom_transform(image)/255.0 for image in images])\n",
    "        \n",
    "        outputs = model(transformed_images)\n",
    "        labels = labels.view(-1, 1).float()\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_end = time.time()\n",
    "    epoch_time = epoch_end - epoch_start\n",
    "    print(f\"Epoch {epoch+1} done in {epoch_time} seconds.\")\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Total time taken: {total_time} seconds\")\n",
    "print(f\"Total time per epoch: {total_time/num_epochs} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f49fbd-5f55-441b-87a9-14f2d8e22e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
