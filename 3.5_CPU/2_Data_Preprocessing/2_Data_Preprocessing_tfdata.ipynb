{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b8e874e-c1db-4fb1-a294-bb23138055d0",
   "metadata": {},
   "source": [
    "# Preprocessing in CPU environment with tfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b0f4ad-e99d-41df-8cf5-419ffee7bf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 10:07:47.626565: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, RandomFlip, RandomRotation, RandomCrop\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0482cdb3-09cd-4477-8176-ae8308ba11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/train_small_npy\"\n",
    "\n",
    "labels_dict = np.load(os.path.join(data_dir, \"labels.npy\"), allow_pickle = True).item()\n",
    "local_paths = list(labels_dict.keys())\n",
    "global_paths = [os.path.join(data_dir, local_path) for local_path in local_paths]\n",
    "labels = list(labels_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b4b2912-adde-457e-9e70-9ddfb9e1f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((global_paths, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c672dd-5f2b-4420-8bdc-7ebb853d4e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_path, label):\n",
    "    def load_np_file(path):\n",
    "        return np.load(path.decode(\"utf-8\"))\n",
    "\n",
    "    image = image = tf.numpy_function(load_np_file, [image_path], tf.uint8)\n",
    "    return image, label\n",
    "\n",
    "dataset = dataset.map(load_data, num_parallel_calls=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7131986f-9c17-495c-b1bd-3879585a3dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 done in 323.1505460739136 seconds.\n",
      "Epoch 2 done in 318.28870964050293 seconds.\n",
      "Epoch 3 done in 327.91578364372253 seconds.\n",
      "Epoch 4 done in 318.7570502758026 seconds.\n",
      "Epoch 5 done in 308.46475768089294 seconds.\n",
      "Epoch 6 done in 320.7336037158966 seconds.\n",
      "Epoch 7 done in 302.6726689338684 seconds.\n",
      "Epoch 8 done in 298.4840362071991 seconds.\n",
      "Epoch 9 done in 307.5554802417755 seconds.\n",
      "Epoch 10 done in 295.64889574050903 seconds.\n",
      "Total time taken: 3121.67312002182 seconds\n",
      "Total time per epoch: 312.16731200218203 seconds\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 48\n",
    "\n",
    "input_layer = Input(shape=(1200, 2000, 3), dtype=tf.float32)\n",
    "x = RandomFlip(\"horizontal_and_vertical\")(input_layer)\n",
    "x = RandomRotation(factor=0.25, fill_mode=\"constant\", fill_value = 0)(x)\n",
    "x = RandomCrop(500, 500)(x)\n",
    "\n",
    "data_augmentation_model = Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "def custom_transform_data(image, label):\n",
    "    image = tf.transpose(image, perm=[1, 2, 0])\n",
    "    image = data_augmentation_model(image)\n",
    "    image = tf.cast(image, dtype=tf.float32) / 255.0\n",
    "    image = tf.transpose(image, perm=[2, 0, 1])\n",
    "    return image, label\n",
    "\n",
    "transformed_dataset = dataset.map(custom_transform_data)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    for images, labels in transformed_dataset.batch(batch_size).as_numpy_iterator():\n",
    "        pass\n",
    "    epoch_end = time.time()\n",
    "    epoch_time = epoch_end - epoch_start\n",
    "    print(f\"Epoch {epoch+1} done in {epoch_time} seconds.\")\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Total time taken: {total_time} seconds\")\n",
    "print(f\"Total time per epoch: {total_time/num_epochs} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
